## 
# Calibration function for Realsense
# Author: Ignacio Ortiz de Zúñiga Mingot
# Date: September 2021
# Course: 2º MII + MIC - ICAI
#
# Purpose: Function to analyze and determine the intrinsic and extrinsic of a 
# Realsense camera but it can be used with any camera. After determining all the
# parameters, it exports them to numpy compress folder. The Realsense driver will
# automatically use this parameters for image correction.
#
# Functions:
#   - unsharp_mask:     Return a sharpened version of the image, using an unsharp mask.
#
#   - IntrinsicsCalibration: Based on OpenCV. Determines the intrinsic parameters of the
#                       camera based on the given images
#
#   - ExtrinsicsCalibration: Based on OpenCV. Determines the extrinsic parameters of the
#                       camera based on the given images
#
# Guide: Print the Pattern.png added in this repository. Make sure when printing to keep the
# original aspect ratio to not deform the image (Check the measurements of the rectangles
# and update the parameters if necessary). Using a flat surface as a base, take images
# of different angles of the chessboard and add them to the Calibration_images folder:
#         Calibration_images
#         ├── Colour
#         ├── Depth
#         ├── IR
#         │   ├── 0000_IR.png
#         │   ├── ...
#         │   ├── 0040_IR.png
# This images and format can easily be obtained with the save function of the Driver.
# But make sure to disconnect the calibration parameters on the class before taking
# the pictures (comment self.setCalibration() on the innit function).
# The just run this script and the new parameters will be created and formatted to be use
# with the driver.
##

import cv2
import numpy as np
import glob
import time
from queue import Queue
from threading import Thread


def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):
    """Return a sharpened version of the image, using an unsharp mask."""
    blurred = cv2.GaussianBlur(image, kernel_size, sigma)
    sharpened = float(amount + 1) * image - float(amount) * blurred
    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))
    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))
    sharpened = sharpened.round().astype(np.uint8)
    if threshold > 0:
        low_contrast_mask = np.absolute(image - blurred) < threshold
        np.copyto(sharpened, image, where=low_contrast_mask)
    return sharpened

def IntrinsicsCalibration(que, obj_points, img_points, shape):
    """Based on OpenCV. Determines the intrisicsparameters of the
        camera based on the given images"""
    # Calibration criteria
    Individual_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10000, 1e-8)
    # Call function
    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
    obj_points, img_points, shape, None, None, criteria=Individual_criteria)
    # Save data on queue
    que.put((ret, mtx, dist, rvecs, tvecs))
    return

def ExtrinsicsCalibration(que, obj_points, img_points_1, img_points_2, mtx_1, dist_1, mtx_2, dist_2, shape):
    """Based on OpenCV. Determines the extrinsic parameters of the
        camera based on the given images"""
    #Calibration flags and criteria
    flags = 0
    flags |= cv2.CALIB_FIX_INTRINSIC    # Don't allow it to change previous intrinsics
    stereocalib_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10000, 1e-8)
    # Call function
    ret_1_2, mtx_1, dist_1, mtx_2, dist_2, R_1_2, T_1_2, E, F = cv2.stereoCalibrate(
        obj_points, img_points_1, img_points_2, mtx_1, dist_1, mtx_2, dist_2,
        shape, criteria=stereocalib_criteria, flags=flags)
    # Save data on queue
    que.put((ret_1_2, mtx_1, dist_1, mtx_2, dist_2, R_1_2, T_1_2, E, F))
    return

######################################################################################
#################################### Calibration #####################################
######################################################################################
# Measure performance
start = time.perf_counter()
print("Calibrating intrinsics & extrinsics...")

############################### Calibration parameters ###############################
# Define chessboard size: number of internal rows and columns corners
chessboard_dimension = (9,6)
chessboard_size = 0.02648    #meters

# Bool parameter to determine if images must be display
display_images = False

# Generate the matrix to save the 3D coordinates of the corners (size = chess_size[0]*chess_size[1], 3)
objp = np.zeros((np.prod(chessboard_dimension), 3), dtype=np.float32)

# The xy coordinate points of the object are generated by np.mgrid and the size (27mm) of each chessboard
objp[:,:2] = np.mgrid[0:chessboard_dimension[0], 0:chessboard_dimension[1]].T.reshape(-1,2)*chessboard_size

# Set termination condition: 30 iterations or change < 0.001
Individual_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10000, 1e-8)

# Load and analize images
print("Analizing Colour & IR images...")
paths = ["Colour", "IR"]
obj_points = []
img_points_Colour = []
img_points_IR = []

# Display images to show correct alingment
calibration_paths_Colour = sorted(glob.glob("./Calibration_Images/" + paths[0] + "/*.png"))
calibration_paths_IR = sorted(glob.glob("./Calibration_Images/" + paths[1] + "/*.png"))

for i in range(len(calibration_paths_Colour)):
    # Read pictures
    img_Colour = cv2.imread(calibration_paths_Colour[i])
    img_IR = cv2.imread(calibration_paths_IR[i])
    img_IR = unsharp_mask(img_IR)   # Sharp image
    # image binaryzation
    gray_Colour = cv2.cvtColor(img_Colour, cv2.COLOR_BGR2GRAY)
    gray_IR = cv2.cvtColor(img_IR, cv2.COLOR_BGR2GRAY)

    # Find the position of the inner corner of the chessboard
    ret_Colour, corners_Colour = cv2.findChessboardCorners(gray_Colour, chessboard_dimension, None)
    ret_IR, corners_IR = cv2.findChessboardCorners(gray_IR, chessboard_dimension, None)

    if ret_Colour == True and ret_IR == True:
        # Add points
        obj_points.append(objp)

        # Sub-pixel corner detection, in corne r detection, accurate corner position
        corners2_Colour = cv2.cornerSubPix(gray_Colour, corners_Colour, (5, 5), (-1, -1), Individual_criteria)
        corners2_IR = cv2.cornerSubPix(gray_IR, corners_IR, (5, 5), (-1, -1), Individual_criteria)
        img_points_Colour.append(corners2_Colour)
        img_points_IR.append(corners2_IR)

        # Mark corner points in the drawing to facilitate viewing results
        if display_images:
            img_Colour = cv2.drawChessboardCorners(img_Colour, chessboard_dimension, corners2_Colour, ret_Colour)
            img_Colour = cv2.resize(img_Colour, (640,480))
            img_IR = cv2.drawChessboardCorners(img_IR, chessboard_dimension, corners2_IR, ret_IR)
            img_IR = cv2.resize(img_IR, (640,480))
            cv2.imshow('Colour', img_Colour)
            cv2.imshow('IR', img_IR)
            cv2.waitKey(100)

cv2.destroyAllWindows()


############################ Determine cameras intrinsics ############################
print('Calculating Colour and IR intrinsics')
# Queues to pass return values
que_Colour = Queue()
que_IR = Queue()
# Creation of threads
t_Colour = Thread(target=IntrinsicsCalibration, args=(que_Colour, obj_points, img_points_Colour, gray_Colour.shape))
t_IR = Thread(target=IntrinsicsCalibration, args=(que_IR, obj_points, img_points_IR, gray_IR.shape))
# Launch threads
t_Colour.start()
t_IR.start()
# Wait for threads to be completed
t_Colour.join()
t_IR.join()
# Extract values from queues
ret_Colour, mtx_Colour, dist_Colour, rvecs_Colour, tvecs_Colour = que_Colour.get()
ret_IR, mtx_IR, dist_IR, rvecs_IR, tvecs_IR = que_IR.get()

############################ Determine cameras extrinsics ############################
print('Calculating Colour and IR extrinsics')
# Creation of threads
t_Colour = Thread(target=ExtrinsicsCalibration, args=(que_Colour, obj_points, img_points_Colour,
    img_points_IR, mtx_Colour, dist_Colour, mtx_IR, dist_IR, gray_IR.shape))

t_IR = Thread(target=ExtrinsicsCalibration, args=(que_IR, obj_points, img_points_IR,
    img_points_Colour, mtx_IR, dist_IR, mtx_Colour, dist_Colour, gray_Colour.shape))
# Launch threads
t_Colour.start()
t_IR.start()
# Wait for threads to be completed
t_Colour.join()
t_IR.join()
# Extract values from queues
ret_Colour_IR, mtx_Colour, dist_Colour, mtx_IR, dist_IR, R_Colour_IR, T_Colour_IR, E_Colour_IR, F_Colour_Ir = que_Colour.get()
ret_IR_Colour, mtx_IR, dist_IR, mtx_Colour, dist_Colour, R_IR_Colour, T_IR_Colour, E_IR_Colour, F_IR_Colour = que_IR.get()
# Save all the parameters calculated
name="Intrinsics&Extrinsics"
np.savez_compressed(name, ret_Colour=ret_Colour, ret_IR=ret_IR, mtx_Colour=mtx_Colour, dist_Colour=dist_Colour, mtx_IR=mtx_IR, dist_IR=dist_IR,
    R_Colour_IR=R_Colour_IR, R_IR_Colour=R_IR_Colour, T_Colour_IR=T_Colour_IR, T_IR_Colour=T_IR_Colour, E_Colour_IR=E_Colour_IR, E_IR_Colour=E_IR_Colour,
    F_Colour_IR=T_Colour_IR, F_IR_Colour=T_IR_Colour,)

# Display some of the calculated parameters
print("#######Colour Camera Matrix#######")
print(mtx_Colour)
print("#######Colour Camera Distortion coefficient#######")
print(dist_Colour)
print("#######IR Camera Matrix#######")
print(mtx_IR)
print("#######IR Camera Distortion coefficient#######")
print(dist_IR)
print("#######Rotation Colour-IR#######")
print(R_Colour_IR)
print("#######Rotation IR-Colour#######")
print(R_IR_Colour)
print("#######Translation Colour-IR#######")
print(T_Colour_IR)
print("#######Translation IR-Colour#######")
print(T_IR_Colour)

# Measure Colour performance
mean_error = 0
for i in range(len(obj_points)):
    imgpoints2, _ = cv2.projectPoints(obj_points[i], rvecs_Colour[i], tvecs_Colour[i], mtx_Colour, dist_Colour)
    error = cv2.norm(img_points_Colour[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)
    mean_error += error
print("Total Colour error: {}".format(mean_error/len(obj_points)))

# Measure IR performance
mean_error = 0
for i in range(len(obj_points)):
    imgpoints2, _ = cv2.projectPoints(obj_points[i], rvecs_IR[i], tvecs_IR[i], mtx_IR, dist_IR)
    error = cv2.norm(img_points_IR[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)
    mean_error += error
print("Total IR error: {}".format(mean_error/len(obj_points)))


# Measure CPU performance
finish = time.perf_counter()
print(f'Finish in {round(finish-start,2)} second(s)')



